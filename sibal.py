import os
import sys
import time
import requests
from notice import Notice
from http.client import HTTPException
from bs4 import BeautifulSoup
from module import notice_module
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

BASE_URL = "https://www.hansung.ac.kr/"
REQUEST_URL = BASE_URL + "hansung/8385/subview.do"

# hrefë¥¼ idë¡œ ë³€í™˜


def extractNumberFrom(string: str):
    return int(''.join(filter(str.isdigit, string)))


def scrapeNotices():
    r"""
    í•œì„±ëŒ€í•™êµ ì „ì²´ ê³µì§€ì‚¬í•­ ì²« í˜ì´ì§€ë¥¼ í—¤ë” ê³µì§€ë¥¼ ì œì™¸í•˜ê³  ìŠ¤í¬ë˜í•‘í•˜ì—¬ :class:`notice` ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•œë‹¤.

    `BASE_URL`ì´ ì˜ëª»ëœ ê²½ìš° :class:`HTTPException`ì„ raiseí•œë‹¤.
    """

    try:
        response = requests.get(REQUEST_URL)
        soup = BeautifulSoup(response.text, "html.parser")

        if response.status_code is not requests.codes['ok']:
            raise HTTPException(
                'ì˜ëª»ëœ URLì„ ìš”ì²­í–ˆìŠµë‹ˆë‹¤. (status code: {response.status_code})')
    except Exception as e:
        raise e

    result = []
    tableRows = soup.select('tbody>tr')
    for tableRow in tableRows:
        # í—¤ë” ê³µì§€ í˜¹ì€ ë¸”ë¼ì¸ë“œ ì²˜ë¦¬ëœ ê³µì§€ëŠ” ê±´ë„ˆë›´ë‹¤.
        if any(className in tableRow.attrs['class'] for className in ['notice', 'blind']):
            continue

        subject = tableRow.select_one('.td-subject > a[href]')
        href = subject['href']

        id = str(extractNumberFrom(href))
        title = subject.text.strip()
        url = BASE_URL + href.removeprefix("/")
        result.append(Notice(id, title, url))
        if result.__len__() == 10:
            break

    return result


def find_new_post(std):
    with open("IDS.txt") as f:
        lines = f.read().splitlines()
    print("ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡")
    print(lines)
    print("ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡")
    count = 0
    for line in lines:
        # print("mmmmmmmmmmmmmmmmmmmmmmmm")
        # print(line)
        if int(std) < int(line):
            count = count+1
    return count

# std ìƒˆë¡œê³ ì¹¨


def std_F5():
    f = open("IDS.txt", 'r')
    std2 = f.readline()
    f.close()
    f = open("std.txt", 'w')
    f.write(std2)
    f.close()


while True:

    f = open("std.txt", 'r')
    std = f.readline()
    f.close()

    testResult = scrapeNotices()
    f = open("IDS.txt", 'w')
    for it in testResult:
        f.write(it.id)
        f.write("\n")
        print("mã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡ã…¡")
        # print(it.id)
    f.close()
    # print(testResult[0].title)
    # print(testResult[0].id)
    # print(testResult[0].url)
    index = find_new_post(std)
    # std_F5()
    if index > 0:
        for i in reversed(range(int(index))):
            message = '\n\n[ğŸ”´ğŸ“ NEW ê³µì§€ ğŸ“ğŸ”´]'
            message = message + '\n\n['+testResult[i].title + ']'
            message = message + '\n['+testResult[i].url + ']'
            notice_module.send_telegram_message(message)
            time.sleep(2)
            print(testResult[i].title)
            print(testResult[i].url)
        std_F5()
    else:
        print("ìƒˆë¡œìš´ ê²Œì‹œë¬¼ì´ ì—†ë‹¤")
